import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from  sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report

df = pd.read_csv("movies_review.csv")


df.head(5)

df.shape


df['category']=df['sentiment'].apply(lambda x: 1 if x=='positive' else 0)

df.head()

x_train,x_test,y_train,y_test=train_test_split(df.review,df.category,test_size=0.2)

x_train.shape


x_test.shape

v=CountVectorizer()
x_train_cv=v.fit_transform(x_train.values)
x_train_cv
x_test_cv=v.fit_transform(x_test.values)
x_test_cv


Random forest classifier using pipeline

plf=Pipeline([
    ('vectorizer',CountVectorizer()),('classifier',RandomForestClassifier(n_estimators=50))
])
plf.fit(x_train,y_train)
y_pred2=plf.predict(x_test)
print(classification_report(y_test,y_pred2))

KNN using pipeline

plff=Pipeline([
    ('vectorizer',CountVectorizer()),('knn',KNeighborsClassifier(n_neighbors=10,metric='euclidean'))
])
plff.fit(x_train,y_train)
y_pred4=plff.predict(x_test)
print(classification_report(y_test,y_pred4))

Naive bayes using pipeline

plff=Pipeline([
    ('vectorizer',CountVectorizer()),('nb',MultinomialNB())
])
plff.fit(x_train,y_train)
y_pred5=plff.predict(x_test)
print(classification_report(y_test,y_pred5))



Both Naive Bayes and Random Forest Classifier works best according to the classification report
